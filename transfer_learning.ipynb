{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T19:26:51.163936Z",
          "iopub.status.busy": "2024-04-26T19:26:51.163362Z",
          "iopub.status.idle": "2024-04-26T19:27:07.561659Z",
          "shell.execute_reply": "2024-04-26T19:27:07.560732Z",
          "shell.execute_reply.started": "2024-04-26T19:26:51.163908Z"
        },
        "id": "zyuopGJw51IB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import keras\n",
        "import keras_nlp\n",
        "import tensorflow as tf\n",
        "import tensorflow.data as tf_data\n",
        "import tensorflow.strings as tf_strings\n",
        "import tensorflow.io as tf_io\n",
        "\n",
        "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lPqzNvC9nuC",
        "outputId": "97ae02fe-9dfd-45b6-9251-605feb1eb499"
      },
      "outputs": [],
      "source": [
        "# train on TPU if appropriate\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
        "print(\"GPUS: \", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "\n",
        "# Check GPU availability\n",
        "print(\"GPU Available:\", tf.test.is_gpu_available())\n",
        "\n",
        "# Check TPU availability\n",
        "tpu_available = False\n",
        "devices = tf.config.list_logical_devices()\n",
        "for device in devices:\n",
        "    if device.device_type == 'TPU':\n",
        "        tpu_available = True\n",
        "        break\n",
        "\n",
        "print(\"TPU Available:\", tpu_available)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWcdHB2q51IB"
      },
      "source": [
        "---\n",
        "**Define model constants**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T19:27:32.702378Z",
          "iopub.status.busy": "2024-04-26T19:27:32.701669Z",
          "iopub.status.idle": "2024-04-26T19:27:32.71016Z",
          "shell.execute_reply": "2024-04-26T19:27:32.708986Z",
          "shell.execute_reply.started": "2024-04-26T19:27:32.702345Z"
        },
        "id": "NKb1h5K651IB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "BATCH_SIZE = 64 # Batch size we train on\n",
        "SEQ_LEN = 512  # Length of training sequences\n",
        "\n",
        "# Training\n",
        "EPOCHS = 40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj9SA17451IC"
      },
      "source": [
        "---\n",
        "**Define the dataset as strings of full recipes**\n",
        "\n",
        "To keep training managable for a laptop, we load the dataset into a tensorflow dataset object. This allows us to load data into memory as needed, opposed to all at once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piQPjC5C51IC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def csv_row_to_json(row):\n",
        "    row = tf_io.decode_csv(records=row, record_defaults=[tf.constant([],dtype=tf.string)] * 7)\n",
        "\n",
        "    title = row[1]\n",
        "    ingredients = row[2]\n",
        "    directions = row[3]\n",
        "    ner = row[6]\n",
        "\n",
        "    return tf_strings.join([\n",
        "        '{\"ner\": ', ner, ', ',\n",
        "        '\"title\": \"', title, '\", ',\n",
        "        '\"ingredients\": ', ingredients, ', ',\n",
        "        '\"directions\": ', directions, '}',\n",
        "    ])\n",
        "\n",
        "\n",
        "dataset = (\n",
        "    tf_data.TextLineDataset(\"RecipeNLG/RecipeNLG_dataset.csv\") # load the csv file line by line\n",
        "    # tf_data.TextLineDataset(\"/kaggle/input/recipenlg/RecipeNLG_dataset.csv\") # load inside kaggle notebook\n",
        "    .skip(1) # skip the header row\n",
        "    .shuffle(buffer_size=256) # store 256 shuffled records in memory at a time before reshuffling and refetching\n",
        "    .map(lambda row: csv_row_to_json(row)) # map each row of the csv to a jsonified recipe\n",
        "    # .ignore_errors() # ignore any errors in the csv file\n",
        "    .apply(tf.data.experimental.ignore_errors()) # ignore any errors in the csv file\n",
        "    .batch(BATCH_SIZE) # batch the dataset to train on multiple records at once\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "**Load the pretrained model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocessor = keras_nlp.models.GPT2CausalLMPreprocessor.from_preset(\n",
        "    \"gpt2_base_en\",\n",
        "    sequence_length=SEQ_LEN,\n",
        ")\n",
        "gpt2_lm = keras_nlp.models.GPT2CausalLM.from_preset(\n",
        "    \"gpt2_base_en\", preprocessor=preprocessor\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "**Define a text generator callback**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TextGenerator(keras.callbacks.Callback):\n",
        "    def __init__(self, k):\n",
        "        self.prompt = '{\"ner\": [\"tomatoes\", \"garlic\", \"pasta\", \"olive oli\",',\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        txt = gpt2_lm.generate(self.prompt)\n",
        "        print(f\"Top-K search generated text: \\n{txt}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzaLSew751ID"
      },
      "source": [
        "---\n",
        "**Finetune the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2Wvlj6h51ID",
        "outputId": "f4199e1b-398a-4ce3-a084-9f475053de06"
      },
      "outputs": [],
      "source": [
        "learning_rate = keras.optimizers.schedules.PolynomialDecay(\n",
        "    5e-5,\n",
        "    decay_steps=dataset.cardinality().numpy() * EPOCHS,\n",
        "    end_learning_rate=0.0,\n",
        ")\n",
        "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "gpt2_lm.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate),\n",
        "    loss=loss,\n",
        "    weighted_metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath='checkpoints/transfer_learning_cp_{epoch:02d}.keras',\n",
        "    save_best_only=False,\n",
        ")\n",
        "text_generation_callback = TextGenerator(k=10)\n",
        "\n",
        "callbacks = [\n",
        "    checkpoint_callback,\n",
        "    text_generation_callback,\n",
        "]\n",
        "\n",
        "gpt2_lm.fit(\n",
        "    dataset, \n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "notebook9003bbc4a7",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 1025978,
          "sourceId": 1728879,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30698,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
