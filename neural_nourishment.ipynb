{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Nourishment\n",
    "\n",
    "This project draws on examples from the Keras tutorials [Text generation with a miniature GPT](https://keras.io/examples/generative/text_generation_with_miniature_gpt/) and [GPT text generation from scratch with KerasNLP](https://keras.io/examples/generative/text_generation_gpt/), as well as the papers [\"Attention is All You Need\"](https://arxiv.org/abs/1706.03762) by Vaswani et al. and [\"Language Models are Few-Shot Listeners\"](https://arxiv.org/abs/2005.14165) by Brown et al.\n",
    "\n",
    "It uses a custom-trained [byte pair encoding tokenization algorithm](https://en.wikipedia.org/wiki/Byte_pair_encoding) and is trained on the [RecipeNLG dataset](https://www.kaggle.com/datasets/paultimothymooney/recipenlg) of 2,231,142 cooking recipes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import neccesary libraries and the Tokenizer class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "import keras_nlp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.data as tf_data\n",
    "import tensorflow.strings as tf_strings\n",
    "\n",
    "from tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Define hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "BATCH_SIZE = 64\n",
    "MIN_STRING_LEN = 512  # Strings shorter than this will be discarded\n",
    "SEQ_LEN = 128  # Length of training sequences, in tokens\n",
    "\n",
    "# Model\n",
    "EMBED_DIM = 256\n",
    "FEED_FORWARD_DIM = 128\n",
    "NUM_HEADS = 3\n",
    "NUM_LAYERS = 2\n",
    "VOCAB_SIZE = 4096  # Limits parameters in model.\n",
    "\n",
    "# Training\n",
    "EPOCHS = 5\n",
    "TOKENIZER_TRAINING_SIZE = 256\n",
    "\n",
    "# Inference\n",
    "NUM_TOKENS_TO_GENERATE = 80\n",
    "\n",
    "# Special tokens\n",
    "START_OF_RECIPE = \"<|recipe_start|>\"\n",
    "END_OF_RECIPE = \"<|recipe_end|>\"\n",
    "SPECIAL_TOKENS = {\n",
    "    START_OF_RECIPE: VOCAB_SIZE - 1,\n",
    "    END_OF_RECIPE: VOCAB_SIZE - 2,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Define the dataset as strings of full recipes**\n",
    "\n",
    "To keep training managable for a laptop, we load the dataset into a tensorflow dataset object. This allows us to load data into memory as needed, opposed to all at once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.py_function(Tout=tf.string)\n",
    "def parse_csv_row(row):\n",
    "    row = tf_strings.as_string(row)\n",
    "    row_values = next(csv.reader([row.numpy().decode('utf-8')]))\n",
    "\n",
    "    ner = eval(row_values[6])\n",
    "    title = row_values[1]\n",
    "    ingredients = eval(row_values[2])\n",
    "    directions = eval(row_values[3])\n",
    "\n",
    "    stringified_recipe = json.dumps({\n",
    "        'ner': ner,\n",
    "        'title': title,\n",
    "        'ingredients': ingredients,\n",
    "        'directions': directions,\n",
    "    })\n",
    "\n",
    "    return START_OF_RECIPE + stringified_recipe + END_OF_RECIPE\n",
    "\n",
    "# load in the csv file line by line\n",
    "dataset = (\n",
    "    tf_data.TextLineDataset(\"RecipeNLG/RecipeNLG_dataset.csv\") # load the csv file line by line\n",
    "    .skip(1) # skip the header row\n",
    "    .shuffle(buffer_size=256) # store 256 shuffled records in memory at a time before reshuffling and refetching\n",
    "    .map(lambda row: parse_csv_row(row)) # map each row of the csv to a stringified recipe\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Train the BPE tokenizer**\n",
    "\n",
    "On a subset of our data, we train a custom byte-pair-encoding tokenizer. Special tokens are used for denoting the beginning and end of recipes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 15:17:16.609816: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer_dataset = \"\"\n",
    "for recipe in dataset.take(TOKENIZER_TRAINING_SIZE):\n",
    "    string_recipe = recipe.numpy().decode('utf-8')\n",
    "    tokenizer_dataset += string_recipe\n",
    "\n",
    "tokenizer.register_special_tokens(SPECIAL_TOKENS)\n",
    "tokenizer.train(tokenizer_dataset, VOCAB_SIZE - len(SPECIAL_TOKENS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Tokenize the dataset**\n",
    "\n",
    "Recipes are batched, tokenized representation, and prepared for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.py_function(Tout=(tf.int32, tf.int32))\n",
    "def prepare_model_inputs(recipe):\n",
    "    recipe = tf_strings.as_string(recipe).numpy().decode('utf-8') # convert the tensor to a string\n",
    "    tokenized_recipe = tokenizer.encode(recipe) # tokenize the string\n",
    "    if len(tokenized_recipe) > SEQ_LEN:\n",
    "        X = tokenized_recipe[:SEQ_LEN]\n",
    "        y = tokenized_recipe[1:SEQ_LEN + 1]\n",
    "    else:\n",
    "        padding = [0] * (SEQ_LEN - len(tokenized_recipe) + 1) # pad shorter token sequences with zeros to ensure uniform size\n",
    "        X = tokenized_recipe[:] + padding[:-1]\n",
    "        y = tokenized_recipe[1:] + padding[:]\n",
    "    \n",
    "    # X is a list of tokens, y is the same list shifted by one token. Both lists are of length SEQ_LEN\n",
    "    return X, y\n",
    "\n",
    "dataset = dataset.map(prepare_model_inputs, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE).batch(BATCH_SIZE) # batch so the model trains on multiple examples at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = keras.layers.Input(shape=(BATCH_SIZE, SEQ_LEN), dtype=\"int32\")\n",
    "\n",
    "    # token embedding layer\n",
    "    embedding_layer = keras_nlp.layers.TokenAndPositionEmbedding(\n",
    "        vocabulary_size=VOCAB_SIZE,\n",
    "        sequence_length=SEQ_LEN,\n",
    "        embedding_dim=EMBED_DIM,\n",
    "        mask_zero=True, # might throw an error if index zero is in the vocabulary(??)\n",
    "    )\n",
    "\n",
    "    # transformer decoders\n",
    "    decoder_layer = keras_nlp.layers.TransformerDecoder(\n",
    "        num_heads=NUM_HEADS,\n",
    "        intermediate_dim=FEED_FORWARD_DIM,\n",
    "    )\n",
    "\n",
    "    # output layer\n",
    "    output_layer = keras.layers.Dense(VOCAB_SIZE)\n",
    "\n",
    "    x = embedding_layer(inputs)\n",
    "    for _ in range(NUM_LAYERS):\n",
    "        x = decoder_layer(x)\n",
    "    outputs = output_layer(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    loss_function = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    perplexity = keras_nlp.metrics.Perplexity(from_logits=True, mask_token_id=0)\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=loss_function, metrics=[perplexity])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ token_and_position… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,081,344</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionE…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_decode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">329,085</span> │ token_and_positi… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ transformer_deco… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,052,672</span> │ transformer_deco… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)             │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ token_and_position… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m,   │  \u001b[38;5;34m1,081,344\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mTokenAndPositionE…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_decode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m,   │    \u001b[38;5;34m329,085\u001b[0m │ token_and_positi… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │ transformer_deco… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m,   │  \u001b[38;5;34m1,052,672\u001b[0m │ transformer_deco… │\n",
       "│                     │ \u001b[38;5;34m4096\u001b[0m)             │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,463,101</span> (9.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,463,101\u001b[0m (9.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,463,101</span> (9.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,463,101\u001b[0m (9.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Fit the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "as_list() is not defined on an unknown TensorShape.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModelCheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdrop_save_at_\u001b[39;49m\u001b[38;5;132;43;01m{epoch}\u001b[39;49;00m\u001b[38;5;124;43m.keras\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ann_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/ann_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[0;31mValueError\u001b[0m: as_list() is not defined on an unknown TensorShape."
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    dataset,\n",
    "    verbose=2,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[\n",
    "        keras.callbacks.ModelCheckpoint(\"drop_save_at_{epoch}.keras\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- X:\n",
      "[[4095  123   34 ...    0    0    0]\n",
      " [4095  123   34 ...    0    0    0]\n",
      " [4095  123   34 ... 1242  274  256]\n",
      " ...\n",
      " [4095  123   34 ...  518 1959  274]\n",
      " [4095  123   34 ...  780  257  256]\n",
      " [4095  123   34 ...  822  274  256]]\n",
      "(64, 128)\n",
      "---- y:\n",
      "[[ 123   34  341 ...    0    0    0]\n",
      " [ 123   34  341 ...    0    0    0]\n",
      " [ 123   34  341 ...  274  256 1791]\n",
      " ...\n",
      " [ 123   34  341 ... 1959  274  256]\n",
      " [ 123   34  341 ...  257  256   50]\n",
      " [ 123   34  341 ...  274  256 2312]]\n",
      "(64, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 15:27:49.081936: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for X, y in dataset.take(1):\n",
    "    print(f\"---- X:\")\n",
    "    print(X.numpy())\n",
    "    print(X.shape)\n",
    "    print(f\"---- y:\")\n",
    "    print(y.numpy())\n",
    "    print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ann_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
